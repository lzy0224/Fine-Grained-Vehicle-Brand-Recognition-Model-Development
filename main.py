import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import cv2
import random

# ================= 1. é¡¹ç›®é…ç½® =================
IMAGE_BASE_PATH = r"C:\Users\Lenovo\Desktop\CV_car\VRID\image"
TRAIN_INDEX_FILE = "re_id_1000_train.txt"
TEST_INDEX_FILE = "re_id_1000_test.txt"

# ResNet50 æ ‡å‡†è¾“å…¥
IMG_SIZE = (224, 224)
BATCH_SIZE = 16  # ä¸ºäº†ç¨³å¦¥ï¼Œç¨å¾®è°ƒå°Batché˜²æ­¢æ˜¾å­˜/å†…å­˜æº¢å‡º
NUM_CLASSES = 10

BRAND_MAPPING = {
    1: "å¥¥è¿ªA4", 2: "æœ¬ç”°é›…é˜", 3: "åˆ«å…‹å›è¶Š", 4: "å¤§ä¼—è¿ˆè…¾",
    5: "ä¸°ç”°èŠ±å† ", 6: "ä¸°ç”°å¡ç½—æ‹‰", 7: "ä¸°ç”°å‡¯ç¾Žç‘ž",
    8: "ç¦ç‰¹ç¦å…‹æ–¯", 9: "æ—¥äº§éªè¾¾", 10: "æ—¥äº§è½©é€¸"
}


# ================= 2. æ•°æ®æµæ°´çº¿ =================
class VehicleDataset:
    def __init__(self, index_file, base_path, img_size=IMG_SIZE):
        self.img_size = img_size
        self.image_paths = []
        self.labels = []
        # åªæœ‰å½“æä¾›äº†æœ‰æ•ˆæ–‡ä»¶åæ—¶æ‰åŠ è½½ï¼Œè§£å†³ dummy æŠ¥é”™
        if index_file and os.path.exists(index_file):
            self._load_index(index_file, base_path)

    def _load_index(self, index_file, base_path):
        print(f"æ­£åœ¨è§£æžç´¢å¼•æ–‡ä»¶: {index_file}...")
        with open(index_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        for line in lines:
            line = line.strip()
            if not line: continue
            parts = line.split('\\')
            if len(parts) >= 3:
                try:
                    brand_id = int(parts[0])
                    path1 = os.path.join(base_path, parts[0], parts[1], parts[-1])
                    path2 = os.path.join(base_path, line)

                    final_path = path1 if os.path.exists(path1) else (path2 if os.path.exists(path2) else None)

                    if final_path:
                        self.image_paths.append(final_path)
                        self.labels.append(brand_id - 1)
                except ValueError:
                    continue
        print(f"âœ… åŠ è½½å®Œæˆï¼Œå…± {len(self.image_paths)} å¼ å›¾ç‰‡")

    def load_image(self, path):
        """è¯»å–å›¾ç‰‡å¹¶è¿›è¡Œé¢„å¤„ç†"""
        try:
            # å°† byte ç±»åž‹çš„ path è½¬ä¸º string (TF ä¼ è¿›æ¥çš„æ˜¯ bytes)
            if isinstance(path, bytes):
                path = path.decode('utf-8')

            img = cv2.imread(path)
            if img is None: raise ValueError("Image invalid")
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, self.img_size)

            # ResNet é¢„å¤„ç†
            img = preprocess_input(img)

            # ðŸ”´ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶è½¬æ¢ä¸º float32
            # ä¹‹å‰çš„é”™è¯¯æ˜¯å› ä¸ºè¿™é‡Œé»˜è®¤å¯èƒ½æ˜¯ float64ï¼Œå¯¼è‡´ TF å´©æºƒ
            return img.astype(np.float32)

        except Exception as e:
            # å‡ºé”™è¿”å›žå…¨0çŸ©é˜µï¼Œé˜²æ­¢ç®¡é“å´©æºƒ
            return np.zeros((*self.img_size, 3), dtype=np.float32)

    def get_dataset_tf(self, batch_size=32, shuffle=False, augment=False):
        if len(self.image_paths) == 0:
            print("âš ï¸ è­¦å‘Šï¼šæ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºç®¡é“")
            return None

        path_ds = tf.data.Dataset.from_tensor_slices(self.image_paths)
        label_ds = tf.data.Dataset.from_tensor_slices(self.labels)
        ds = tf.data.Dataset.zip((path_ds, label_ds))

        def _process_path(path, label):
            # å‘Šè¯‰ TF è¿™ä¸ª numpy_function è‚¯å®šè¿”å›ž float32
            img = tf.numpy_function(self.load_image, [path], tf.float32)
            img.set_shape([*self.img_size, 3])
            return img, label

        ds = ds.map(_process_path, num_parallel_calls=tf.data.AUTOTUNE)

        if augment:
            data_augmentation = tf.keras.Sequential([
                layers.RandomFlip("horizontal"),
                layers.RandomRotation(0.1),
                layers.RandomContrast(0.1)
            ])
            ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y),
                        num_parallel_calls=tf.data.AUTOTUNE)

        if shuffle:
            ds = ds.shuffle(buffer_size=1000)

        ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)
        return ds


# ================= 3. æ¨¡åž‹æž„å»º (æœ¬åœ°æƒé‡ä¼˜å…ˆ) =================
def build_model_resnet(input_shape, num_classes):
    # ðŸ”´ ä¿®å¤ï¼šä¼˜å…ˆåŠ è½½æœ¬åœ° ResNet50 æƒé‡
    weight_filename = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'
    weight_path = os.path.join(os.getcwd(), weight_filename)

    if os.path.exists(weight_path):
        print(f"ðŸ“¦ å‘çŽ°æœ¬åœ°æƒé‡æ–‡ä»¶: {weight_filename}")
        weights_source = weight_path
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°æƒé‡ {weight_filename}ï¼Œå°è¯•è”ç½‘ä¸‹è½½...")
        weights_source = 'imagenet'

    try:
        base_model = ResNet50(weights=weights_source, include_top=False, input_shape=input_shape)
        print("âœ… ResNet50 åŸºåº§æž„å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
        print("âš ï¸ åˆ‡æ¢åˆ°éšæœºåˆå§‹åŒ–æ¨¡å¼ (æ•ˆæžœå¯èƒ½å—å½±å“)")
        base_model = ResNet50(weights=None, include_top=False, input_shape=input_shape)

    # é˜¶æ®µä¸€ï¼šå†»ç»“
    base_model.trainable = False

    inputs = keras.Input(shape=input_shape)
    x = base_model(inputs, training=False)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.5)(x)
    x = layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-4))(x)
    x = layers.Dropout(0.3)(x)
    outputs = layers.Dense(num_classes, activation='softmax')(x)

    model = keras.Model(inputs, outputs, name="ResNet50_Vehicle_Net")
    return model, base_model


# ================= 4. ä¸šåŠ¡ç³»ç»Ÿ =================
class VehicleRecognitionSystem:
    def __init__(self, model, detection_threshold=0.65):
        self.model = model
        self.detection_threshold = detection_threshold

    def predict_pipeline(self, img_array):
        img_batch = np.expand_dims(img_array, axis=0)
        probs = self.model.predict(img_batch, verbose=0)[0]
        max_conf = np.max(probs)
        pred_idx = np.argmax(probs)

        has_vehicle = max_conf >= self.detection_threshold

        return {
            "has_vehicle": has_vehicle,
            "detection_score": float(max_conf),
            "brand": BRAND_MAPPING[pred_idx + 1] if has_vehicle else "èƒŒæ™¯/æœªçŸ¥",
        }


# ================= 5. ä¸»ç¨‹åº =================
def main():
    print("\n>>> 1. æ•°æ®é›†å‡†å¤‡")
    train_indexer = VehicleDataset(TRAIN_INDEX_FILE, IMAGE_BASE_PATH)
    test_indexer = VehicleDataset(TEST_INDEX_FILE, IMAGE_BASE_PATH)

    if len(train_indexer.image_paths) == 0: return

    # åˆ’åˆ†éªŒè¯é›†
    X_train_paths, X_val_paths, y_train, y_val = train_test_split(
        train_indexer.image_paths, train_indexer.labels,
        test_size=0.2, stratify=train_indexer.labels, random_state=42
    )

    # é‡æ–°æž„å»ºå¯¹è±¡ (ä¼ å…¥ None é¿å… dummy æŠ¥é”™)
    train_ds_obj = VehicleDataset(None, None)
    train_ds_obj.image_paths, train_ds_obj.labels = X_train_paths, y_train

    val_ds_obj = VehicleDataset(None, None)
    val_ds_obj.image_paths, val_ds_obj.labels = X_val_paths, y_val

    train_ds = train_ds_obj.get_dataset_tf(batch_size=BATCH_SIZE, shuffle=True, augment=True)
    val_ds = val_ds_obj.get_dataset_tf(batch_size=BATCH_SIZE, shuffle=False)
    test_ds = test_indexer.get_dataset_tf(batch_size=BATCH_SIZE, shuffle=False)

    if train_ds is None: return

    # --- é˜¶æ®µä¸€ ---
    print("\n>>> 2. é˜¶æ®µä¸€: å†»ç»“ä¸»å¹²ï¼Œè®­ç»ƒåˆ†ç±»å¤´ (Warm-up)")
    model, base_model = build_model_resnet((224, 224, 3), NUM_CLASSES)

    model.compile(optimizer=keras.optimizers.Adam(1e-3),
                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    # é˜¶æ®µä¸€ä¸éœ€è¦è·‘å¤ªå¤šè½®ï¼Œåªè¦ä¸åŠ¨å°±è¡Œ
    model.fit(train_ds, validation_data=val_ds, epochs=3, verbose=1)

    # --- é˜¶æ®µäºŒ ---
    print("\n>>> 3. é˜¶æ®µäºŒ: è§£å†»ä¸»å¹²ï¼Œåˆ†å±‚å¾®è°ƒ (Fine-tuning)")
    base_model.trainable = True

    model.compile(optimizer=keras.optimizers.Adam(1e-5),  # æžä½Žå­¦ä¹ çŽ‡
                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    callbacks = [
        keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, verbose=1),
        keras.callbacks.ModelCheckpoint('best_resnet_finetuned.h5', save_best_only=True, verbose=1)
    ]

    model.fit(train_ds, validation_data=val_ds, epochs=15, callbacks=callbacks, verbose=1)

    # --- è¯„ä¼° ---
    print("\n>>> 4. æœ€ç»ˆè¯„ä¼°")
    loss, acc = model.evaluate(test_ds, verbose=1)
    print(f"ðŸ”¥ æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®çŽ‡: {acc * 100:.2f}%")

    # --- æ¼”ç¤º ---
    print("\n>>> 5. ç³»ç»Ÿæ¼”ç¤º")
    system = VehicleRecognitionSystem(model)
    indices = random.sample(range(len(test_indexer.image_paths)), 3)
    for idx in indices:
        path = test_indexer.image_paths[idx]
        img = test_indexer.load_image(path)
        res = system.predict_pipeline(img)
        print(f"æ–‡ä»¶: {os.path.basename(path)} | ç»“æžœ: {res['brand']} ({res['detection_score']:.2f})")


if __name__ == "__main__":
    main()